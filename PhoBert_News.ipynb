{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HoaNguyen55/PhoBert_News_Classification/blob/main/PhoBert_News.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjcGQlXlqu8k",
        "outputId": "f1180376-6e56-4d6b-ded0-d7c9a3cbd758"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "# !mkdir /content/drive/MyDrive/News # First time create new folder\n",
        "os.chdir('/content/drive/MyDrive/News/')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lkC3jBZY1136"
      },
      "outputs": [],
      "source": [
        "# !git clone https://github.com/HoaNguyen55/PhoBert_News_Classification.git\n",
        "os.chdir('/content/drive/MyDrive/News/PhoBert_News_Classification')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "poqMovjG2Eq3",
        "outputId": "36b95506-06a5-4dbb-8a9a-2f6679642f16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: vncorenlp in /usr/local/lib/python3.7/dist-packages (1.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from vncorenlp) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->vncorenlp) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->vncorenlp) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->vncorenlp) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->vncorenlp) (3.0.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.22.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (5.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.layers import Embedding, Dense, Dropout, Bidirectional, LSTM, Input, GlobalAveragePooling1D, Flatten\n",
        "import tensorflow_hub as hub\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "from sklearn import datasets\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "!pip install vncorenlp\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpvJYT-ZgfoF"
      },
      "outputs": [],
      "source": [
        "# First time create new folder\n",
        "\n",
        "# !mkdir -p vncorenlp/models/wordsegmenter  \n",
        "# !wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/VnCoreNLP-1.1.1.jar  \n",
        "# !wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/vi-vocab  \n",
        "# !wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/wordsegmenter.rdr  \n",
        "# !mv VnCoreNLP-1.1.1.jar vncorenlp/   \n",
        "# !mv vi-vocab vncorenlp/models/wordsegmenter/  \n",
        "# !mv wordsegmenter.rdr vncorenlp/models/wordsegmenter/  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1qBxCd8J8xd",
        "outputId": "0a50f569-cfb5-4f73-aafd-a2def2980a27"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "from vncorenlp import VnCoreNLP\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "import os\n",
        "from transformers import RobertaForSequenceClassification, RobertaConfig, AdamW, RobertaTokenizer, RobertaTokenizerFast, RobertaModel, AutoTokenizer\n",
        "from datetime import datetime\n",
        "import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "classes = ['__label__sống_trẻ', \n",
        "           '__label__thời_sự', \n",
        "           '__label__công_nghệ', \n",
        "           '__label__sức_khỏe', \n",
        "           '__label__giáo_dục', \n",
        "           '__label__xe_360', \n",
        "           '__label__thời_trang', \n",
        "           '__label__du_lịch', \n",
        "           '__label__âm_nhạc', \n",
        "           '__label__xuất_bản', \n",
        "           '__label__nhịp_sống', \n",
        "           '__label__kinh_doanh', \n",
        "           '__label__pháp_luật', \n",
        "           '__label__ẩm_thực', \n",
        "           '__label__thế_giới', \n",
        "           '__label__thể_thao', \n",
        "           '__label__giải_trí', \n",
        "           '__label__phim_ảnh']\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\", local_files_only=True)\n",
        "\n",
        "def make_mask(batch_ids):\n",
        "    batch_mask = []\n",
        "    for ids in batch_ids:\n",
        "        mask = [int(token_id > 0) for token_id in ids]\n",
        "        batch_mask.append(mask)\n",
        "    return torch.tensor(batch_mask)\n",
        "\n",
        "def dataloader_from_text(text_file=None, tokenizer=None, classes=[], savetodisk=None, loadformdisk=None, segment=False, max_len=256, batch_size=16, infer=False):\n",
        "    ids_padded, masks, labels = [], [], []\n",
        "    if loadformdisk == None:\n",
        "        #segementer\n",
        "        if segment:\n",
        "            rdrsegmenter = VnCoreNLP(\"./vncorenlp/VnCoreNLP-1.1.1.jar\", annotators=\"wseg\", max_heap_size='-Xmx500m')\n",
        "        texts = []\n",
        "        print(\"LOADDING TEXT FILE\")\n",
        "        with open(text_file, 'r') as f_r:\n",
        "            for sample in tqdm(f_r):\n",
        "                if infer:\n",
        "                    text = sample.strip()\n",
        "                    if segment:\n",
        "                        text = rdrsegmenter.tokenize(text)\n",
        "                        text = ' '.join([' '.join(x) for x in text])\n",
        "                    texts.append(text)\n",
        "                else:\n",
        "                    splits = sample.strip().split(\" \",1)\n",
        "                    label = classes.index(splits[0])\n",
        "                    text = splits[1]\n",
        "                    if segment:\n",
        "                        text = rdrsegmenter.tokenize(text)\n",
        "                        text = ' '.join([' '.join(x) for x in text])\n",
        "                    labels.append(label)\n",
        "                    texts.append(text)\n",
        "\n",
        "        print(\"TEXT TO IDS\")\n",
        "        ids = []\n",
        "        for text in tqdm(texts):\n",
        "            encoded_sent = tokenizer.encode(text)\n",
        "            ids.append(encoded_sent)\n",
        "\n",
        "        del texts\n",
        "        # print(\"PADDING IDS\")\n",
        "        ids_padded = pad_sequences(ids, maxlen=max_len, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n",
        "        del ids\n",
        "        # print(\"CREATE MASK\")\n",
        "        # for sent in tqdm(ids_padded):\n",
        "        #     masks.append(make_mask(sent))\n",
        "\n",
        "        if savetodisk != None and not infer:\n",
        "            with open(savetodisk, 'wb') as f:\n",
        "                pickle.dump(ids_padded, f)\n",
        "                # pickle.dump(masks, f)\n",
        "                pickle.dump(labels, f)\n",
        "            print(\"SAVED IDS DATA TO DISK\")\n",
        "    else:\n",
        "        print(\"LOAD FORM DISK\")\n",
        "        if loadformdisk != None:\n",
        "            try:\n",
        "                with open(savetodisk, 'rb') as f:\n",
        "                    ids_padded = pickle.load(ids_padded, f)\n",
        "                    # masks = pickle.load(masks, f)\n",
        "                    labels = pickle.load(labels, f)\n",
        "                print(\"LOADED IDS DATA FORM DISK\")\n",
        "            except:\n",
        "                print(\"LOAD DATA FORM DISK ERROR!\")\n",
        "                \n",
        "    print(\"CONVERT TO TORCH TENSOR\")\n",
        "    ids_inputs = torch.tensor(ids_padded)\n",
        "    del ids_padded\n",
        "    # masks = torch.tensor(masks)\n",
        "    if not infer:\n",
        "        labels = torch.tensor(labels)\n",
        "\n",
        "    print(\"CREATE DATALOADER\")\n",
        "    if infer:\n",
        "        # input_data = TensorDataset(ids_inputs, masks)\n",
        "        input_data = TensorDataset(ids_inputs)\n",
        "    else:\n",
        "        input_data = TensorDataset(ids_inputs, labels)\n",
        "        # input_data = TensorDataset(ids_inputs, masks, labels)\n",
        "    \n",
        "    X_train, X_test, y_train, y_test = train_test_split(input_data, labels, test_size=0.1, shuffle=False)\n",
        "    \n",
        "    input_sampler_X = SequentialSampler(X_train)\n",
        "    input_sampler_Y = SequentialSampler(X_test)\n",
        "    train_dataloader = DataLoader(X_train, sampler=input_sampler_X, batch_size=batch_size)\n",
        "    test_dataloader = DataLoader(X_test, sampler=input_sampler_Y, batch_size=batch_size)\n",
        "\n",
        "    print(\"LOAD DATA ALL DONE\")\n",
        "    return train_dataloader, test_dataloader\n",
        "\n",
        "def dataloader_from_text_only(text_file=None, tokenizer=None, classes=[], savetodisk=None, loadformdisk=None, segment=False, max_len=256, batch_size=16, infer=False):\n",
        "    ids_padded, masks, labels = [], [], []\n",
        "    if loadformdisk == None:\n",
        "        #segementer\n",
        "        if segment:\n",
        "            rdrsegmenter = VnCoreNLP(\"./vncorenlp/VnCoreNLP-1.1.1.jar\", annotators=\"wseg\", max_heap_size='-Xmx500m')\n",
        "        texts = []\n",
        "        print(\"LOADDING TEXT FILE\")\n",
        "        with open(text_file, 'r') as f_r:\n",
        "            for sample in tqdm(f_r):\n",
        "                if infer:\n",
        "                    text = sample.strip()\n",
        "                    if segment:\n",
        "                        text = rdrsegmenter.tokenize(text)\n",
        "                        text = ' '.join([' '.join(x) for x in text])\n",
        "                    texts.append(text)\n",
        "                else:\n",
        "                    splits = sample.strip().split(\" \",1)\n",
        "                    label = classes.index(splits[0])\n",
        "                    text = splits[1]\n",
        "                    if segment:\n",
        "                        text = rdrsegmenter.tokenize(text)\n",
        "                        text = ' '.join([' '.join(x) for x in text])\n",
        "                    labels.append(label)\n",
        "                    texts.append(text)\n",
        "\n",
        "        print(\"TEXT TO IDS\")\n",
        "        ids = []\n",
        "        for text in tqdm(texts):\n",
        "            encoded_sent = tokenizer.encode(text)\n",
        "            ids.append(encoded_sent)\n",
        "\n",
        "        del texts\n",
        "        # print(\"PADDING IDS\")\n",
        "        ids_padded = pad_sequences(ids, maxlen=max_len, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n",
        "        del ids\n",
        "        # print(\"CREATE MASK\")\n",
        "        # for sent in tqdm(ids_padded):\n",
        "        #     masks.append(make_mask(sent))\n",
        "\n",
        "        if savetodisk != None and not infer:\n",
        "            with open(savetodisk, 'wb') as f:\n",
        "                pickle.dump(ids_padded, f)\n",
        "                # pickle.dump(masks, f)\n",
        "                pickle.dump(labels, f)\n",
        "            print(\"SAVED IDS DATA TO DISK\")\n",
        "    else:\n",
        "        print(\"LOAD FORM DISK\")\n",
        "        if loadformdisk != None:\n",
        "            try:\n",
        "                with open(savetodisk, 'rb') as f:\n",
        "                    ids_padded = pickle.load(ids_padded, f)\n",
        "                    # masks = pickle.load(masks, f)\n",
        "                    labels = pickle.load(labels, f)\n",
        "                print(\"LOADED IDS DATA FORM DISK\")\n",
        "            except:\n",
        "                print(\"LOAD DATA FORM DISK ERROR!\")\n",
        "                \n",
        "    print(\"CONVERT TO TORCH TENSOR\")\n",
        "    ids_inputs = torch.tensor(ids_padded)\n",
        "    del ids_padded\n",
        "    # masks = torch.tensor(masks)\n",
        "    if not infer:\n",
        "        labels = torch.tensor(labels)\n",
        "\n",
        "    print(\"CREATE DATALOADER\")\n",
        "    if infer:\n",
        "        # input_data = TensorDataset(ids_inputs, masks)\n",
        "        input_data = TensorDataset(ids_inputs)\n",
        "    else:\n",
        "        input_data = TensorDataset(ids_inputs, labels)\n",
        "        # input_data = TensorDataset(ids_inputs, masks, labels)\n",
        "        \n",
        "    input_sampler = SequentialSampler(input_data)\n",
        "    dataloader = DataLoader(input_data, sampler=input_sampler, batch_size=batch_size)\n",
        "\n",
        "    print(\"len dataloader:\", len(dataloader))\n",
        "    print(\"LOAD DATA ALL DONE\")\n",
        "    return dataloader, input_data, labels\n",
        "\n",
        "def predict_text(model, text, classes, tokenizer, max_len=256):\n",
        "  model.cuda()\n",
        "  ids = tokenizer.encode(text)\n",
        "  ids_padded = pad_sequences([ids], maxlen=max_len, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n",
        "  mask = [[int(token_id > 0)] for token_id in ids_padded[0]]\n",
        "  input_ids = torch.tensor(ids_padded)\n",
        "  input_mask = torch.tensor(mask)\n",
        "  with torch.no_grad():\n",
        "      logits = model(input_ids.cuda(), \n",
        "                      attention_mask=input_mask.cuda(),\n",
        "                      labels=None)[0]\n",
        "      logits = logits.detach().cpu().numpy()\n",
        "      pred_flat_axis1 = np.argmax(logits, axis=1).flatten()\n",
        "      # print(pred_flat_axis1)\n",
        "\n",
        "  print(\"[PREDICT] \\nTEXT: {}\\nLABEL: {}\".format(text, classes[pred_flat_axis1[1]]))\n",
        "\n",
        "# Validate model on new valid.txt, not relate with train.txt and test.tx file\n",
        "def classification_report_model(model, file_dir, tokenizer, classes=[]):\n",
        "      valid_path = file_dir\n",
        "      test_dataloader, test_data_raw, test_labels = dataloader_from_text_only(valid_path, \n",
        "                                                                            tokenizer=tokenizer, \n",
        "                                                                            classes=classes, \n",
        "                                                                            savetodisk=None, \n",
        "                                                                            batch_size=32)\n",
        "\t    # Store label to compare with trained model and then do classification report\n",
        "      true_labels = []\n",
        "      model.cuda()\n",
        "\n",
        "      for step, batch in enumerate(test_dataloader):\n",
        "        b_input_ids = batch[0].cuda()\n",
        "        b_input_mask = make_mask(batch[0]).cuda()\n",
        "        b_labels = batch[1].cuda()\n",
        "        model.zero_grad()\n",
        "        with torch.no_grad():\n",
        "          outputs = model(b_input_ids, \n",
        "\t                      attention_mask=b_input_mask, \n",
        "\t                      labels=b_labels\n",
        "\t                      )\n",
        "          logits = outputs[1].detach().cpu().numpy()\n",
        "          pred_flat = np.argmax(logits, axis=1).flatten().tolist()\n",
        "          true_labels.extend(pred_flat)\n",
        "       \n",
        "          # print(test_labels.tolist())\n",
        "          # print(true_labels)\n",
        "      print(classification_report(test_labels.tolist(), true_labels, target_names=classes))\n",
        "\n",
        "def load_model(file_dir):\n",
        "  # Load model from saved file\n",
        "  load_model = torch.load(file_dir)\n",
        "  model = BERTClassifier(len(classes))\n",
        "  model.load_state_dict(load_model['model_state_dict']) # Load state dict, include input_ids and attention_mask\n",
        "  \n",
        "  return model\n",
        "\n",
        "def train_plot_model(classes, train_dataloader, test_dataloader, epochs):\n",
        "  # Bert model\n",
        "  bert_classifier_model = BERTClassifier(len(classes))\n",
        "  # Initialize model\n",
        "  bert_classifier_trainer = ClassifierTrainner(bert_model=bert_classifier_model, \n",
        "                                              train_dataloader=train_dataloader, \n",
        "                                              valid_dataloader=test_dataloader, \n",
        "                                              epochs=epochs, \n",
        "                                              cuda_device=\"0\", # Default to use GPU, \"cpu\"=cpu or \"0\"=gpu0, \"1\"=gpu1, \n",
        "                                              new_file=True) # Create new folder\n",
        "  # Training model \n",
        "  accur_train, loss_train, accur_val, loss_val = bert_classifier_trainer.train_classifier()\n",
        "\n",
        "  # Plot model\n",
        "  bert_classifier_trainer.plot_model(accur_train, loss_train, accur_val, loss_val)\n",
        "\n",
        "def init_load_text(file_dir, bert_model=\"vinai/phobert-base\", max_len=256):\n",
        "  train_path = file_dir\n",
        "  MAX_LEN = max_len\n",
        "  tokenizer = AutoTokenizer.from_pretrained(bert_model, local_files_only=True)\n",
        "  train_dataloader, test_dataloader = dataloader_from_text(train_path, \n",
        "                                                            tokenizer=tokenizer, \n",
        "                                                            classes=classes, \n",
        "                                                            savetodisk=None, \n",
        "                                                            max_len=MAX_LEN, \n",
        "                                                            batch_size=16)\n",
        "  \n",
        "  return train_dataloader, test_dataloader\n",
        "\n",
        "class ROBERTAClassifier(torch.nn.Module):\n",
        "    def __init__(self, num_labels, bert_model, dropout_rate=0.3):\n",
        "        super(ROBERTAClassifier, self).__init__()\n",
        "        if bert_model != None:\n",
        "            self.roberta = bert_model\n",
        "        else:\n",
        "            self.roberta = RobertaModel.from_pretrained(\"./vinai/phobert-base\")\n",
        "        self.d1 = torch.nn.Dropout(dropout_rate)\n",
        "        self.l1 = torch.nn.Linear(768, 64)\n",
        "        self.bn1 = torch.nn.LayerNorm(64)\n",
        "        self.d2 = torch.nn.Dropout(dropout_rate)\n",
        "        self.l2 = torch.nn.Linear(64, num_labels)\n",
        "        \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        _, x = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        x = self.d1(x)\n",
        "        x = self.l1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = torch.nn.Tanh()(x)\n",
        "        x = self.d2(x)\n",
        "        x = self.l2(x)\n",
        "        return x \n",
        "\n",
        "class BERTClassifier(torch.nn.Module):\n",
        "    def __init__(self, num_labels):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        bert_classifier_config = RobertaConfig.from_pretrained(\n",
        "            \"./vinai/phobert-base/config.json\",\n",
        "            from_tf=False,\n",
        "            num_labels = num_labels,\n",
        "            output_hidden_states=False,\n",
        "            )\n",
        "        print(\"LOAD BERT PRETRAIN MODEL\")\n",
        "        self.bert_classifier = RobertaForSequenceClassification.from_pretrained(\n",
        "            \"./vinai/phobert-base/pytorch_model.bin\",\n",
        "            config=bert_classifier_config\n",
        "            )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels):\n",
        "        output = self.bert_classifier(input_ids=input_ids,\n",
        "                                    token_type_ids=None,\n",
        "                                    attention_mask=attention_mask,\n",
        "                                    labels=labels\n",
        "                                    )\n",
        "        return output\n",
        "\n",
        "class ClassifierTrainner():\n",
        "    def __init__(self, bert_model, train_dataloader, valid_dataloader, epochs=10, cuda_device=\"cpu\", save_dir=None, new_file=True):\n",
        "\n",
        "        if cuda_device == \"cpu\":\n",
        "            self.device == torch.device(\"cpu\")\n",
        "        else:\n",
        "            self.device = torch.device('cuda:{}'.format(cuda_device))\n",
        "\n",
        "        self.model = bert_model\n",
        "        if save_dir != None and os.path.exists(save_dir):\n",
        "            print(\"Load weight from file:{}\".format(save_dir))\n",
        "            self.save_dir = save_dir\n",
        "            epcho_checkpoint_path = glob.glob(\"{}/model_epoch*\".format(self.save_dir))\n",
        "            if len(epcho_checkpoint_path) == 0:\n",
        "                print(\"No checkpoint found in: {}\\nCheck save_dir...\".format(self.save_dir))\n",
        "            else:\n",
        "                self.load_checkpoint(epcho_checkpoint_path)\n",
        "                print(\"Restore weight successful from: {}\".format(epcho_checkpoint_path))\n",
        "        else:\n",
        "            if (new_file):\n",
        "              self.save_dir = datetime.now().strftime(\"%d-%m-%Y_%H-%M-%S\")\n",
        "              os.makedirs(self.save_dir)\n",
        "              print(\"Training new model, save to: {}\".format(self.save_dir))\n",
        "\n",
        "        self.train_dataloader = train_dataloader\n",
        "        self.valid_dataloader = valid_dataloader\n",
        "        self.epochs = epochs\n",
        "        # self.batch_size = batch_size\n",
        "\n",
        "    def save_checkpoint(self, save_path):\n",
        "        state_dict = {'model_state_dict': self.model.state_dict()}\n",
        "        torch.save(state_dict, save_path)\n",
        "        print(f'Model saved to ==> {save_path}')\n",
        "\n",
        "    def load_checkpoint(self, load_path):\n",
        "        state_dict = torch.load(load_path, map_location=self.device)\n",
        "        print(f'Model restored from <== {load_path}')\n",
        "        self.model.load_state_dict(state_dict['model_state_dict'])\n",
        "\n",
        "    @staticmethod    \n",
        "    def flat_accuracy(preds, labels):\n",
        "        pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "        labels_flat = labels.flatten()\n",
        "        F1_score = f1_score(pred_flat, labels_flat, average='macro')\n",
        "        return accuracy_score(pred_flat, labels_flat), F1_score\n",
        "\n",
        "    def train_classifier(self):\n",
        "        self.model.to(self.device)\n",
        "        param_optimizer = list(self.model.named_parameters())\n",
        "        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "        optimizer_grouped_parameters = [\n",
        "            {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "            {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "            ]\n",
        "        optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5, correct_bias=False) # lr is recommended from BERT paper\n",
        "        loss_train_list = []\n",
        "        acurracy_train_list = []\n",
        "        acurracy_val_list = []\n",
        "        loss_val_list = []\n",
        "        best_valid_loss = 999999\n",
        "        best_eval_accuracy = 0\n",
        "                \n",
        "        for epoch_i in range(0, self.epochs):\n",
        "            print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, self.epochs))\n",
        "            print('Training...')\n",
        "            total_loss = 0\n",
        "            train_accuracy = 0\n",
        "            train_f1 = 0\n",
        "            nb_train_steps = 0\n",
        "            self.model.train()\n",
        "            \n",
        "            for step, batch in enumerate(self.train_dataloader):\n",
        "                b_input_ids = batch[0].to(self.device)\n",
        "                b_input_mask = make_mask(batch[0]).to(self.device)\n",
        "                b_labels = batch[1].to(self.device)\n",
        "\n",
        "                self.model.zero_grad()\n",
        "                outputs = self.model(b_input_ids, \n",
        "                                    attention_mask=b_input_mask, \n",
        "                                    labels=b_labels\n",
        "                                    )\n",
        "                loss = outputs[0]\n",
        "                total_loss += loss.item()\n",
        "                \n",
        "                logits = outputs[1].detach().cpu().numpy()\n",
        "                label_ids = b_labels.cpu().numpy()\n",
        "                tmp_train_accuracy, tmp_train_f1 = self.flat_accuracy(logits, label_ids)\n",
        "                train_accuracy += tmp_train_accuracy\n",
        "                train_f1 += tmp_train_f1\n",
        "                nb_train_steps += 1\n",
        "                \n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
        "                optimizer.step()\n",
        "                print(\"[TRAIN] Epoch {}/{} | Batch {}/{} | Train Loss={} | Train Acc={}\".format(epoch_i+1, self.epochs, step, len(self.train_dataloader), loss.item(), tmp_train_accuracy))\n",
        "                \n",
        "                ''' In training, every step divisible by 100 or current step == max length of dataloader\n",
        "                    Then validate dataset, and store the model which has the best result\n",
        "                '''\n",
        "                if step % 50 == 0:\n",
        "                    if step > 0:\n",
        "                      accur_val, loss_val = self.validate_classifier(epoch_i+1, best_valid_loss, best_eval_accuracy)\n",
        "                      best_eval_accuracy = accur_val\n",
        "                      best_valid_loss = loss_val\n",
        "                      acurracy_val_list.append(accur_val)\n",
        "                      loss_val_list.append(loss_val)\n",
        "\n",
        "                      avg_train_loss = total_loss / len(self.train_dataloader)\n",
        "                      acurracy_each_steps = train_accuracy/nb_train_steps\n",
        "                      print(\" Train Accuracy: {0:.4f}\".format(acurracy_each_steps))\n",
        "                      acurracy_train_list.append(acurracy_each_steps)\n",
        "                      print(\" Train F1 score: {0:.4f}\".format(train_f1/nb_train_steps))\n",
        "                      print(\" Train Loss: {0:.4f}\".format(avg_train_loss))\n",
        "                      loss_train_list.append(avg_train_loss)\n",
        "            \n",
        "        print(\"Training complete!\")\n",
        "        return acurracy_train_list, loss_train_list, acurracy_val_list, loss_val_list\n",
        "\n",
        "    def validate_classifier(self, currentEpoch, best_valid_loss, best_eval_accuracy):\n",
        "        print(\"Running Validation...\")\n",
        "        self.model.eval()\n",
        "        eval_loss, eval_accuracy = 0, 0\n",
        "        nb_eval_steps, nb_eval_examples = 0, 0\n",
        "        eval_f1 = 0\n",
        "        for batch in self.valid_dataloader:\n",
        "            b_input_mask = make_mask(batch[0]).to(self.device)\n",
        "            batch = tuple(t.to(self.device) for t in batch)\n",
        "            b_input_ids, b_labels = batch\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(b_input_ids, \n",
        "                                    attention_mask=b_input_mask,\n",
        "                                    labels=b_labels\n",
        "                                    )\n",
        "                tmp_eval_loss, logits = outputs[0], outputs[1]\n",
        "                logits = logits.detach().cpu().numpy()\n",
        "                label_ids = b_labels.cpu().numpy()\n",
        "                tmp_eval_accuracy, tmp_eval_f1 = self.flat_accuracy(logits, label_ids)\n",
        "                eval_accuracy += tmp_eval_accuracy\n",
        "                eval_loss += tmp_eval_loss\n",
        "                eval_f1 += tmp_eval_f1\n",
        "                nb_eval_steps += 1\n",
        "\n",
        "        loss_val = eval_loss/nb_eval_steps\n",
        "        print(\" Valid Loss: {0:.4f}\".format(loss_val))\n",
        "        accur_val = eval_accuracy/nb_eval_steps\n",
        "        print(\" Valid Accuracy: {0:.4f}\".format(accur_val))\n",
        "        print(\" Valid F1 score: {0:.4f}\".format(eval_f1/nb_eval_steps))\n",
        "        \n",
        "        print(\"best_valid_loss = {0:.4f}\".format(best_valid_loss))\n",
        "        print(\"eval_loss = {0:.4f}\".format(loss_val))\n",
        "\n",
        "        if eval_loss > best_valid_loss:\n",
        "            best_valid_loss_path = \"{}/model_best_valoss_{}epochs.pth\".format(self.save_dir, self.epochs)\n",
        "            self.save_checkpoint(best_valid_loss_path)\n",
        "        \n",
        "        print(\"best_eval_accuracy = {0:.4f}\".format(best_eval_accuracy))\n",
        "        print(\"eval_accuracy = {0:.4f}\".format(accur_val))\n",
        "\n",
        "        if accur_val > best_eval_accuracy:\n",
        "            best_eval_accuracy_path = \"{}/model_best_valacc{}epochs.pth\".format(self.save_dir, self.epochs)\n",
        "            self.save_checkpoint(best_eval_accuracy_path)\n",
        "        \n",
        "        if currentEpoch == self.epochs:\n",
        "            epoch_path = \"{}/model_{}epoch.pth\".format(self.save_dir, currentEpoch)\n",
        "            self.save_checkpoint(epoch_path)\n",
        "            # os.remove(\"{}/model_{}epoch.pth\".format(self.save_dir, currentEpoch-1))\n",
        "\n",
        "        return accur_val, loss_val.item()\n",
        "\n",
        "    def plot_model(self, acurracy_train_list, loss_train_list, acurracy_val_list, loss_val_list):\n",
        "      # list all data in history\n",
        "      # summarize history for accuracy\n",
        "      plt.plot(acurracy_train_list)\n",
        "      plt.plot(acurracy_val_list)\n",
        "      # formatter = matplotlib.ticker.StrMethodFormatter(\"{x:.3f}\")\n",
        "      # plt.gca().yaxis.set_major_formatter(formatter)\n",
        "      plt.title('model accuracy')\n",
        "      plt.ylabel('accuracy')\n",
        "      plt.xlabel('epoch')\n",
        "      plt.legend(['train', 'vald'], loc='upper left')\n",
        "      plt.show()\n",
        "      # summarize history for loss\n",
        "      plt.plot(loss_train_list)\n",
        "      plt.plot(loss_val_list)\n",
        "      plt.title('model loss')\n",
        "      plt.ylabel('loss')\n",
        "      plt.xlabel('epoch*step') # Check number of step = 10 ==> 526%50 = 10\n",
        "      plt.legend(['train', 'vald'], loc='upper left')\n",
        "      plt.show()\n",
        "\n",
        "    def predict_dataloader(self, dataloader, classes, tokenizer):\n",
        "        for batch in dataloader:\n",
        "            batch = tuple(t.to(self.device) for t in batch)\n",
        "            b_input_ids, b_input_mask = batch\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(b_input_ids, \n",
        "                                    attention_mask=b_input_mask,\n",
        "                                    labels=None\n",
        "                                    )\n",
        "                logits = outputs\n",
        "                logits = logits.detach().cpu().numpy()\n",
        "                pred_flat = np.argmax(logits, axis=1).flatten()\n",
        "                print(\"[PREDICT] {}:{}\".format(classes[int(pred_flat)], tokenizer.decode(b_input_ids)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "collapsed": true,
        "id": "qXX9e6NmHMzk",
        "outputId": "5675f926-4ff5-497f-9a4c-658b900811b5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/root/.cache/huggingface/hub/models--vinai--phobert-base/snapshots/667b55927a1571811539f27c0f374429a1c75759/vocab.txt'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#@title\n",
        "from huggingface_hub import hf_hub_download\n",
        "# snapshot_download(repo_id=\"vinai/phobert-base\")\n",
        "hf_hub_download(repo_id=\"vinai/phobert-base\", filename=\"config.json\")\n",
        "hf_hub_download(repo_id=\"vinai/phobert-base\", filename=\"pytorch_model.bin\")\n",
        "hf_hub_download(repo_id=\"vinai/phobert-base\", filename=\"bpe.codes\")\n",
        "hf_hub_download(repo_id=\"vinai/phobert-base\", filename=\"tokenizer.json\")\n",
        "hf_hub_download(repo_id=\"vinai/phobert-base\", filename=\"vocab.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VS6ilClhHkEO"
      },
      "outputs": [],
      "source": [
        "# First time create new folder\n",
        "\n",
        "# !mkdir vinai\n",
        "# !chmod 777 vinai\n",
        "# !mkdir vinai/phobert-base\n",
        "# !chmod 777 vinai/phobert-base\n",
        "# !cp /root/.cache/huggingface/hub/models--vinai--phobert-base/snapshots/667b55927a1571811539f27c0f374429a1c75759/* vinai/phobert-base/."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLJlMVOCWMMT",
        "outputId": "689d0f7a-7f18-4363-c44a-f792920afc67"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LOADDING TEXT FILE\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "9335it [00:00, 37485.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TEXT TO IDS\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/9335 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (576 > 256). Running this sequence through the model will result in indexing errors\n",
            "100%|██████████| 9335/9335 [00:25<00:00, 362.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONVERT TO TORCH TENSOR\n",
            "CREATE DATALOADER\n",
            "LOAD DATA ALL DONE\n"
          ]
        }
      ],
      "source": [
        "# Load text file\n",
        "train_dataloader, test_dataloader = init_load_text(file_dir='train-1.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmaSILyFgzV5"
      },
      "outputs": [],
      "source": [
        "# Train model and plot accuracy and loss\n",
        "train_plot_model(classes, train_dataloader, test_dataloader, epochs=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7B6kfjgdA6h",
        "outputId": "43be4a43-cf0a-4f18-d12e-f5714baa7e58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LOAD BERT PRETRAIN MODEL\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at ./vinai/phobert-base/pytorch_model.bin were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at ./vinai/phobert-base/pytorch_model.bin and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = load_model(file_dir='./06-10-2022_09-24-11/model_8epoch.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "90zF-HKeo2bE",
        "outputId": "e13ef46e-da51-4740-eefc-a4565ec94ae8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LOADDING TEXT FILE\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "501it [00:00, 30967.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TEXT TO IDS\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/501 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (480 > 256). Running this sequence through the model will result in indexing errors\n",
            "100%|██████████| 501/501 [00:01<00:00, 282.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONVERT TO TORCH TENSOR\n",
            "CREATE DATALOADER\n",
            "len dataloader: 16\n",
            "LOAD DATA ALL DONE\n",
            "                     precision    recall  f1-score   support\n",
            "\n",
            "  __label__sống_trẻ       1.00      1.00      1.00        25\n",
            "   __label__thời_sự       0.97      1.00      0.98        31\n",
            " __label__công_nghệ       1.00      1.00      1.00        38\n",
            "  __label__sức_khỏe       0.95      1.00      0.98        21\n",
            "  __label__giáo_dục       1.00      0.96      0.98        25\n",
            "    __label__xe_360       1.00      0.96      0.98        25\n",
            "__label__thời_trang       1.00      1.00      1.00        33\n",
            "   __label__du_lịch       1.00      1.00      1.00        24\n",
            "   __label__âm_nhạc       1.00      1.00      1.00        40\n",
            "  __label__xuất_bản       1.00      1.00      1.00        28\n",
            " __label__nhịp_sống       1.00      1.00      1.00        23\n",
            "__label__kinh_doanh       1.00      1.00      1.00        19\n",
            " __label__pháp_luật       1.00      0.97      0.99        34\n",
            "   __label__ẩm_thực       1.00      1.00      1.00        21\n",
            "  __label__thế_giới       1.00      1.00      1.00        30\n",
            "  __label__thể_thao       0.97      1.00      0.98        30\n",
            "  __label__giải_trí       1.00      1.00      1.00        28\n",
            "  __label__phim_ảnh       1.00      1.00      1.00        26\n",
            "\n",
            "           accuracy                           0.99       501\n",
            "          macro avg       0.99      0.99      0.99       501\n",
            "       weighted avg       0.99      0.99      0.99       501\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Report based on validation input file\n",
        "classification_report_model(model, file_dir='valid.txt', tokenizer=tokenizer, classes=classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "jbgZGVonay1w",
        "outputId": "e56c2316-d817-439e-ace6-397124572d9b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LOADDING TEXT FILE\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "9335it [00:00, 50333.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TEXT TO IDS\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/9335 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (576 > 256). Running this sequence through the model will result in indexing errors\n",
            "100%|██████████| 9335/9335 [00:22<00:00, 414.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONVERT TO TORCH TENSOR\n",
            "CREATE DATALOADER\n",
            "len dataloader: 292\n",
            "LOAD DATA ALL DONE\n",
            "                     precision    recall  f1-score   support\n",
            "\n",
            "  __label__sống_trẻ       0.99      0.98      0.99       510\n",
            "   __label__thời_sự       1.00      1.00      1.00       496\n",
            " __label__công_nghệ       1.00      0.98      0.99       532\n",
            "  __label__sức_khỏe       0.98      0.99      0.99       496\n",
            "  __label__giáo_dục       0.99      0.99      0.99       528\n",
            "    __label__xe_360       0.99      0.99      0.99       502\n",
            "__label__thời_trang       1.00      0.99      0.99       521\n",
            "   __label__du_lịch       1.00      0.99      0.99       551\n",
            "   __label__âm_nhạc       1.00      1.00      1.00       554\n",
            "  __label__xuất_bản       0.99      1.00      0.99       519\n",
            " __label__nhịp_sống       0.97      1.00      0.99       497\n",
            "__label__kinh_doanh       0.98      0.99      0.99       498\n",
            " __label__pháp_luật       1.00      0.99      1.00       543\n",
            "   __label__ẩm_thực       1.00      1.00      1.00       520\n",
            "  __label__thế_giới       1.00      0.99      0.99       549\n",
            "  __label__thể_thao       0.99      1.00      1.00       507\n",
            "  __label__giải_trí       1.00      1.00      1.00       487\n",
            "  __label__phim_ảnh       0.99      1.00      1.00       525\n",
            "\n",
            "           accuracy                           0.99      9335\n",
            "          macro avg       0.99      0.99      0.99      9335\n",
            "       weighted avg       0.99      0.99      0.99      9335\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Report based on train input file\n",
        "classification_report_model(model, file_dir='train-1.txt', classes=classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OJoDW2JSne7",
        "outputId": "2e1da6a5-6c22-4b27-d0eb-ce36f8cace31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[PREDICT] \n",
            "TEXT: vì sao phim võ thuật hoa ngữ thế giới kinh ngạc phim chiếu rạp bộ phim cổ trang điện ảnh hoa ngữ thế giới kinh ngạc ngọa hổ tàng long đoạt oscar hạng mục phim nói tiếng nước ngoài xuất sắc 2001 nhắc đầu tiên bộ phim ngọa hổ tàng long đạo diễn tài ba lý an 2000 bộ phim điện ảnh châu á trở thành hiện tượng nền điện ảnh thế giới thập kỷ trôi bộ phim niềm tự hào điện ảnh trung quốc trở thành bộ phim nước ngoài doanh thu cao mỹ đồng thời bộ phim đem đạo diễn lý an loạt tượng vàng oscar 2001 vô số giải thưởng lớn nhỏ bộ phim xuất hiện pha song kiếm thuộc kinh điển tên tuổi bộ phim lý an ông đau đầu chọn địa điểm quay phù hợp phim hoàng thôn nơi thích hợp khung cảnh kiếm hiệp hấp dẫn hoàng thôn unesco ghi nhận di sản văn hóa thế giới đậm dấu ấn văn hóa trung quốc đúng ý đồ nghệ thuật đạo diễn lý an ngoài ra bộ phim góp mặt đạo diễn chỉ đạo võ thuật viên hòa bình đóng vai trò quan trọng bộ ba phim ăn khách ma trận kill bill bộ phim anh hùng bộ phim xuất sắc đạo diễn trương nghệ mưu quy tụ ngôi sao sáng màn bạc trung hoa lý liên kiệt lương triều vĩ chân tử đan trương mạn ngọc trần đạo minh chương tử di bộ phim dựa truyền thuyết kinh kha lý liên kiệt thủ vai nhân vật chính vô danh đối với anh hùng trương nghệ mưu thú nhận đầu tiên ông thực hiện bộ phim võ thuật đầy tham vọng bởi vậy đạo diễn xem xét chi tiết ông chỉ đạo đường kiếm lý liên kiệt giọt lệ lăn gò má trương mạn ngọc chính xác đường tơ kẽ tóc cảnh quay tốn ba giờ đồng hồ thường sử dụng phim giây cảnh chiến đấu trương mạn ngọc chương tử di bối cảnh diễn mùa lá rụng đạo diễn thuê vùng nội mông quay video chiếc lá gửi ông xem trương nghệ mưu theo dõi điện thoại xem lá vàng độ nào đạt yêu cầu ông đoàn phim vượt nghìn cây số tận nơi quay cảnh chiếc lá rơi tất cả mọi rời trường quay lúc quá nửa đêm thì trương nghệ mưu chỉnh sửa kết quả làm việc đạo diễn hy vọng nỗ lực mệt mỏi ông bù đắp hưởng ứng nhiệt tình khán giả bộ phim ra mắt kết quả anh hùng trương nghệ mưu lọt đề cử oscar phim nói tiếng nước ngoài xuất sắc 2002 tuy nhiên bộ phim đoạt giải người ta rằng viện hàn lâm điện ảnh hoa kỳ không bao giờ trao liên tiếp giải oscar thể loại phim võ thuật cổ trang như thế nhiếp ẩn nương the assasin tác phẩm đề tài kiếm hiệp tiếp theo đạo diễn hầu hiếu hiền trình làng bộ phim nhận lời phê bình tích cực giới phê bình giả thưởng đạo diễn xuất sắc liên hoan phim cannes 2015 thậm chí tác phẩm điện ảnh nhăm nhe tham vọng đề cử tượng vàng oscar hạng mục phim nói tiếng nước ngoài xuất sắc 2016 bộ phim khán giả cảm thấy mãn nhãn bởi thước phim xây dựng tuyệt đẹp chân thực kinh ngạc bối cảnh tuyệt đẹp bộ phim đạo diễn hầu hiếu hiền tiết lộ hầu hết cảnh quay chúng tôi thực hiện khu vực mông cổ phía bắc trung quốc tỉnh hồ bắc tôi bất ngờ nhìn khu rừng bạch dương bạc bờ hồ giữ nguyên vẻ hoang sơ bối cảnh phim tạo khuôn hình không thể đẹp đặc biệt phim khán giả bắt gặp khuôn hình nông dân làm việc mảnh đất họ nông dân thực sự công việc đúng thường ngày họ tôi cố gắng giữ nguyên tất cả cho dù vài chi tiết đúng kịch bản mong muốn\n",
            "LABEL: __label__phim_ảnh\n"
          ]
        }
      ],
      "source": [
        "# Demo predict a paragraph \n",
        "text = 'vì sao phim võ thuật hoa ngữ thế giới kinh ngạc phim chiếu rạp bộ phim cổ trang điện ảnh hoa ngữ thế giới kinh ngạc ngọa hổ tàng long đoạt oscar hạng mục phim nói tiếng nước ngoài xuất sắc 2001 nhắc đầu tiên bộ phim ngọa hổ tàng long đạo diễn tài ba lý an 2000 bộ phim điện ảnh châu á trở thành hiện tượng nền điện ảnh thế giới thập kỷ trôi bộ phim niềm tự hào điện ảnh trung quốc trở thành bộ phim nước ngoài doanh thu cao mỹ đồng thời bộ phim đem đạo diễn lý an loạt tượng vàng oscar 2001 vô số giải thưởng lớn nhỏ bộ phim xuất hiện pha song kiếm thuộc kinh điển tên tuổi bộ phim lý an ông đau đầu chọn địa điểm quay phù hợp phim hoàng thôn nơi thích hợp khung cảnh kiếm hiệp hấp dẫn hoàng thôn unesco ghi nhận di sản văn hóa thế giới đậm dấu ấn văn hóa trung quốc đúng ý đồ nghệ thuật đạo diễn lý an ngoài ra bộ phim góp mặt đạo diễn chỉ đạo võ thuật viên hòa bình đóng vai trò quan trọng bộ ba phim ăn khách ma trận kill bill bộ phim anh hùng bộ phim xuất sắc đạo diễn trương nghệ mưu quy tụ ngôi sao sáng màn bạc trung hoa lý liên kiệt lương triều vĩ chân tử đan trương mạn ngọc trần đạo minh chương tử di bộ phim dựa truyền thuyết kinh kha lý liên kiệt thủ vai nhân vật chính vô danh đối với anh hùng trương nghệ mưu thú nhận đầu tiên ông thực hiện bộ phim võ thuật đầy tham vọng bởi vậy đạo diễn xem xét chi tiết ông chỉ đạo đường kiếm lý liên kiệt giọt lệ lăn gò má trương mạn ngọc chính xác đường tơ kẽ tóc cảnh quay tốn ba giờ đồng hồ thường sử dụng phim giây cảnh chiến đấu trương mạn ngọc chương tử di bối cảnh diễn mùa lá rụng đạo diễn thuê vùng nội mông quay video chiếc lá gửi ông xem trương nghệ mưu theo dõi điện thoại xem lá vàng độ nào đạt yêu cầu ông đoàn phim vượt nghìn cây số tận nơi quay cảnh chiếc lá rơi tất cả mọi rời trường quay lúc quá nửa đêm thì trương nghệ mưu chỉnh sửa kết quả làm việc đạo diễn hy vọng nỗ lực mệt mỏi ông bù đắp hưởng ứng nhiệt tình khán giả bộ phim ra mắt kết quả anh hùng trương nghệ mưu lọt đề cử oscar phim nói tiếng nước ngoài xuất sắc 2002 tuy nhiên bộ phim đoạt giải người ta rằng viện hàn lâm điện ảnh hoa kỳ không bao giờ trao liên tiếp giải oscar thể loại phim võ thuật cổ trang như thế nhiếp ẩn nương the assasin tác phẩm đề tài kiếm hiệp tiếp theo đạo diễn hầu hiếu hiền trình làng bộ phim nhận lời phê bình tích cực giới phê bình giả thưởng đạo diễn xuất sắc liên hoan phim cannes 2015 thậm chí tác phẩm điện ảnh nhăm nhe tham vọng đề cử tượng vàng oscar hạng mục phim nói tiếng nước ngoài xuất sắc 2016 bộ phim khán giả cảm thấy mãn nhãn bởi thước phim xây dựng tuyệt đẹp chân thực kinh ngạc bối cảnh tuyệt đẹp bộ phim đạo diễn hầu hiếu hiền tiết lộ hầu hết cảnh quay chúng tôi thực hiện khu vực mông cổ phía bắc trung quốc tỉnh hồ bắc tôi bất ngờ nhìn khu rừng bạch dương bạc bờ hồ giữ nguyên vẻ hoang sơ bối cảnh phim tạo khuôn hình không thể đẹp đặc biệt phim khán giả bắt gặp khuôn hình nông dân làm việc mảnh đất họ nông dân thực sự công việc đúng thường ngày họ tôi cố gắng giữ nguyên tất cả cho dù vài chi tiết đúng kịch bản mong muốn'\n",
        "\n",
        "predict_text(model, classes=classes, text=text, tokenizer=tokenizer, max_len=256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWlaOVVUv8Gv",
        "outputId": "b895f5cb-572a-4414-ebd6-d0020545470f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting python-docx\n",
            "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 7.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from python-docx) (4.9.1)\n",
            "Building wheels for collected packages: python-docx\n",
            "  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184507 sha256=31d606720ecd3a2c7f0cb3874392307be9410a490acadcdcb5eddf3b0cf27e49\n",
            "  Stored in directory: /root/.cache/pip/wheels/f6/6f/b9/d798122a8b55b74ad30b5f52b01482169b445fbb84a11797a6\n",
            "Successfully built python-docx\n",
            "Installing collected packages: python-docx\n",
            "Successfully installed python-docx-0.8.11\n"
          ]
        }
      ],
      "source": [
        "!pip install python-docx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 233,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZV9-GeFCv-tj",
        "outputId": "2ce0b042-3906-48e2-c293-ca6240202ea6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "399\n",
            "\n",
            "Submission list\n",
            "Paper index: [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [24], [25], [27], [29], [30], [32], [33], [34], [35], [38], [42], [43], [46], [48], [49], [51], [52], [54], [59], [61], [64], [65], [66], [68], [72], [73], [74], [78], [79], [82], [83], [84], [85], [86], [87], [89], [90], [91], [92], [93], [95], [96], [98], [101], [102], [105], [106], [108], [111], [113], [115], [117], [118], [119], [121], [123], [124], [125], [126], [127], [128], [129], [130], [131], [132], [133], [134], [135], [136], [139], [140], [141], [142], [143], [144], [145], [146], [147], [148], [149], [150], [151], [152], [154], [155], [157], [158], [159], [160], [161], [162], [163], [164], [165], [166], [189], [190], [191], [192], [193]\n",
            "[1] Brijeshkumar Y. Panchal (charotar university of science and technology, India.) and Gaurang Chauhan (ITsouls, Vdodara). Design and implementation of android application to extract text from images by using tesseract for English and Hindi.\n",
            "Abstract. The proposed Implementation is on the Android Application to extract using Tesseract OCR in which the following concepts will be used, which are Adaptive Thresholding, Connected Component, Fine Lines, and Recognize Word. Using this Optical Character Recognition (OCR) Technology, an Application generated text which is printed on a clean, B/W or colorful background can be converted into a computer readable form ASCII. With the help of this Android Application using Tesseract OCR, the system has two ways for Text Extraction. The first one is to capture a photo while the second one uploads an image from the gallery after that system can proceed for as per the user requirement which portion of the image they want to crop or edit. After editing the picture, it converts into the text. This Android Application is for two languages, English and Hindi.\n",
            "\n",
            "Track:   NLP\n",
            "Time:   Mar 24, 10:33\n",
            "Decision:   REJECT\n",
            "Keywords:   Text Extraction, Android Application, OCR, Image Processing, Tesseract 4, Tesseract 3, Tesseract\n",
            "Paper:   ✔\n",
            "Topics:   \n",
            "[2] Quách Thị Bích Nhường (Trường Đại học Công nghệ Đồng Nai), Trần Văn Ninh (Trường Đại học Công nghệ Đồng Nai), Đỗ Phúc Thịnh (Trường Đại học Công nghệ Đồng Nai) and Phan Mạnh Thường (Trường Đại học Công nghệ Đồng Nai). TÁI TẠO MÔ HÌNH 3D CỦA ĐỐI TƯỢNG TỪ ẢNH PHÁC THẢO 2.5D.\n",
            "Abstract. Hiện nay, trong rất nhiều lĩnh vực như: y khoa, điện ảnh, kiến trúc… mô hình 3D được ứng dụng rất nhiều. Tuy nhiên, để xây dựng mô hình 3D sẽ cần rất nhiều thông tin của đối tượng. Vì thế, việc tái tạo mô hình 3D từ bản phác thảo 2.5D là hoàn toàn cần thiết. Đầu tiên, so với hình dạng 3D đầy đủ, các bản phác thảo 2.5D dễ dàng được phục hồi hơn từ hình ảnh 2D; các mô hình phục hồi bản phác thảo 2.5D cũng có nhiều khả năng chuyển từ các bộ dữ liệu tổng hợp sang dữ liệu thực tế. Thứ hai, để tái tạo hình dạng 3D từ bản phác thảo 2.5D, các hệ thống có thể học hoàn toàn từ các bộ dữ liệu tổng hợp. Thứ ba là có thể dễ dàng hiển thị các bản phác thảo 2.5D mà không cần mô hình hóa đối tượng trong ảnh thật. Trong bài báo này, chúng tôi nghiên cứu một mô hình có thể huấn luyện từ đầu đến cuối bằng cách tích hợp các mô hình học sâu, có khả năng ước tính tuần tự từ các ảnh phác thảo 2.5D thành hình dạng đối tượng 3D và tinh chỉnh hình dạng này. Thực nghiệm cho thấy, khi so sánh trên bộ dữ liệu ShapeNet Core55, phương pháp này cho kết quả tốt hơn so với các phương pháp trước đây.\n",
            "\n",
            "Track:   CV\n",
            "Time:   Apr 17, 08:49\n",
            "Decision:   ACCEPT\n",
            "Keywords:   Tái tạo mô hình, mạng học sâu, ảnh 2.5D, single-view, reconstruction\n",
            "Paper:   ✔\n",
            "Topics:   \n",
            "[3] Nguyễn Thái Anh (Khoa CNTT, Đại học Văn Lang, Tp.HCM. Địa chỉ: 313/6A Nguyễn Trãi, P7 Q5. TPHCM) and Phan Hồ Viết Trường (Khoa CNTT, Đại học Văn Lang, Tp.HCM. Địa chỉ: 313/6A Nguyễn Trãi, P7 Q5. TPHCM). PHÁT TRIỂN HỆ KHUYẾN NGHỊ VIỆC LÀM CHO SINH VIÊN CÔNG NGHỆ THÔNG TIN THEO NĂNG LỰC HỌC TẬP ĐÁP ỨNG NHU CẦU DOANH NGHIỆP.\n",
            "Abstract. Hệ khuyến nghị là một hệ thống gợi ý sản phẩm, dịch vụ cho người dùng dựa vào lịch sử mua hàng của họ. Hệ khuyến nghị được ứng dụng trong nhiều lĩnh vực khác nhau như du lịch, giáo dục, tin tức, âm nhạc…Tuy nhiên, rất ít nghiên cứu dùng hệ khuyến nghị giới thiệu việc làm cho sinh viên khi chưa tốt nghiệp. Bài báo này trình bày một giải pháp xây dựng hệ khuyến nghị việc làm cho sinh viên ngành Công nghệ thông tin đang theo học các chuyên ngành Khoa học dữ liệu, Kỹ thuật phần mềm và Mạng máy tính tại trường Đại học Văn Lang. Nghiên cứu này sử dụng kỹ thuật lọc nội dung để đo lường độ tương đồng giữa các môn học mà sinh viên đã đạt điểm cao với nhu cầu của doanh nghiệp Công nghệ thông tin. Sau đó, hệ thống sẽ chọn 5 công ty phù hợp nhất để gởi thông tin tuyển dụng đến hộp thư cá nhân của sinh viên. Dữ liệu thử nghiệm được thu thập từ bảng điểm của khoảng 500 sinh viên năm ba và năm cuối đang theo học các chuyên ngành trên tại Đại học Văn Lang. Kết quả thử nghiệm đánh giá giải pháp đề xuất đạt hiệu quả tốt hơn so với các độ đo phổ biến như Jaccard, Cosine, TF-IDF + cosine, Word2Vec + cosine. Giải pháp này có thể được áp dụng cho các khoa khác tại trường Đại học Văn Lang.\n",
            "\n",
            "Track:   IS\n",
            "Time:   May 03, 04:38\n",
            "Decision:   ACCEPT\n",
            "Keywords:   Hệ khuyến nghị, độ đo tương đồng, rút trích thông tin, hệ khuyến nghị việc làm\n",
            "Paper:   ✔\n",
            "Topics:   \n",
            "[4] Van-Tan Bui (university of economics - technology for industries). MỘT MÔ HÌNH KẾT HỢP ĐO LƯỜNG ĐỘ TƯƠNG TỰ NGỮ NGHĨA CỦA CẶP CÂU TIẾNG VIỆT DỰA TRÊN ĐỘ TƯƠNG QUAN TỪ VỰNG VÀ MÔ HÌNH NHÚNG TỪ.\n",
            "Abstract. Đo lường độ tương tự ngữ nghĩa cặp câu (sentence similarity) là một bài toán quan trọng và có nhiều ứng dụng trong lĩnh vực xử lý ngôn ngữ tự nhiên.  Sentence similarity được sử dụng để nâng cao hiệu năng trong nhiều hệ thống như dịch máy, nhận dạng tiếng nói, hỏi đáp tự động, tóm tắt văn bản. Mặc dù vậy, để lượng giá chính xác độ tương tự ngữ nghĩa giữa các câu vẫn còn là một thách thức. Cho đến thời điểm hiện tại, chưa có phương pháp sentence similarity nào khai thác các đặc trưng riêng của tiếng Việt được đề xuất, cũng như chưa có bộ dữ liệu sentence similarity cho tiếng Việt được công bố. Trong bài viết này, chúng tôi đề xuất một phương pháp đo lường độ tương tự ngữ nghĩa của cặp câu tiếng Việt dựa trên độ đo kết hợp giữa độ tương quan từ vựng và độ tương tự theo nhúng từ; xây dựng một bộ dữ liệu đánh giá các mô hình sentence similarity tiếng Việt. Cuối cùng, chúng tôi thực nghiệm và đánh giá phương pháp được đề xuất trên bộ dữ liệu đã xây dựng.\n",
            "\n",
            "Track:   NLP\n",
            "Time:   May 04, 08:43\n",
            "Decision:   REJECT\n",
            "Keywords:   độ tương tự câu, sentence similarity, word embeddings\n",
            "Paper:   ✔\n",
            "Topics:   \n",
            "[5] Phan Tấn Quốc (Sai Gon University). Phân tích một số thuật toán metaheuristic giải bài toán max clique.\n",
            "Abstract. Max clique (maximum clique problem) is a combinatorial optimization problem that has many applications in science and engineering such as social networks, telecommunication networks, bioinformatics, etc. Max clique is a problem of class NP-hard. There are many approaches to solving the max clique problem such as algorithms to find exact solutions, heuristic algorithms, metaheuristic algorithms, etc. In this paper, we analyze the approach to solving the max clique problem in the direction of metaheuristic algorithms. We evaluate the quality of these research based on the experimental data system DIMACS. Our analysis can be useful information for further research on max clique problems.\n",
            "\n",
            "Track:   AI\n",
            "Time:   May 06, 08:09\n",
            "Decision:   REJECT\n",
            "Keywords:   Maximum clique problem, social networks, heuristic algorithm, metaheuristic algorithm, DIMACS\n",
            "Paper:   ✔\n",
            "Topics:   Trí tuệ nhân tạo và ứng dụng (Artificial Intelligence and Its Applications)\n",
            "[6] Hoàng Trung Chính (Khoa Công nghệ Thông tin, Đại học Khoa học Tự nhiên, ĐHQG-HCM), Nguyễn Hồng Bửu Long (Khoa Công nghệ Thông tin, Đại học Khoa học Tự nhiên, ĐHQG-HCM) and Lương An Vinh (Khoa Công nghệ Thông tin, Đại học Công nghệ Sài Gòn). DỊCH MÁY MẠNG NEURAL ANH – VIỆT THEO CHỦ ĐỀ.\n",
            "Abstract. Trong những năm gần đây, dịch máy mạng neural đã và đang được áp dụng vào nhiều lĩnh vực khác nhau và đạt được nhiều thành tựu đáng kể. Trong lĩnh vực dịch máy theo chủ đề, mặc dù dịch máy mạng neural đã đạt được nhiều kết quả cao, tuy nhiên, mô hình vẫn cần được huấn luyện bởi nguồn dữ liệu được dịch thủ công bởi con người vốn tốn nhiều chi phí và thời gian. Trong bài báo này, chúng tôi nghiên cứu một phương pháp nhằm tăng chất lượng dịch theo chủ đề với nguồn tài nguyên hạn chế. Việc chọn lọc dữ liệu giàu thông tin trước khi tinh chỉnh một mô hình sẵn có giúp đạt được độ chính xác cao hơn so với việc chọn dữ liệu nghèo thông tin, từ đó giúp tiết kiệm chi phí trong việc dịch thủ công. Cụ thể hơn, chúng tôi thử nghiệm phương pháp chọn lọc mới và đạt được kết quả tốt hơn từ 0.47 đến 2.31 điểm BLEU trong các bộ ngữ liệu Anh – Việt khác nhau.\n",
            "\n",
            "Track:   NLP\n",
            "Time:   May 08, 05:27\n",
            "Decision:   ACCEPT\n",
            "Keywords:   Dịch máy, Dịch máy mạng neural, Dịch máy theo chủ đề\n",
            "Paper:   ✔\n",
            "Topics:   \n",
            "[7] Đỗ Sĩ Trường (Đại Học Lạc Hồng), Phạm Công Xuyên (Đại Học Lạc Hồng), Trần Thanh Phương (Đại Học Lạc Hồng) and Nguyễn Thanh Tùng (Đại Học Lạc Hồng). MỘT PHIÊN BẢN CẢI TIẾN CỦA THUẬT TOÁN MMR  ĐỂ GOM CỤM DỮ LIỆU PHÂN LOẠI.\n"
          ]
        }
      ],
      "source": [
        "import docx\n",
        "# doc = docx.Document('TESU CBE 29 Employee Job Description Evaluation - Final Approved.docx')  # Creating word reader object.\n",
        "doc = docx.Document('FAIR2021_submissions_2022-10-10_1665416741.docx')\n",
        "data = \"\"\n",
        "fullText = []\n",
        "# for para in doc.paragraphs:\n",
        "#     print(para)\n",
        "#     fullText.append(para.text)\n",
        "#     data = '\\n'.join(fullText)\n",
        "\n",
        "# print(data)\n",
        "print(len(doc.paragraphs))\n",
        "for i in range(len(doc.paragraphs)):\n",
        "  print(doc.paragraphs[i].text)\n",
        "  if (i>20):\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 333,
      "metadata": {
        "id": "Ov0wbEjb2OaF"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def extract_abstract(doc):\n",
        "  abstractLst = []\n",
        "  prefix = [\"Abstract.\", \n",
        "            \"Tóm Tắt -\", \n",
        "            \"Tóm Tắt-\", \n",
        "            \"TÓM TẮT -\", \n",
        "            \"TÓM TẮT—\",\n",
        "            \"Tóm tắt -\",\n",
        "            \"TÓM TẮT —\",\n",
        "            \"Abstract -\",\n",
        "            \"Abstract-\",\n",
        "            \"—\"]\n",
        "  for i in range(len(doc.paragraphs)):\n",
        "    match = re.search('(?<!\\S)Abstract[\\.].+[[a-zA-Z0-9a-zA-Z_ÀÁÂÃÈÉÊẾÌÍÒÓÔÕÙÚĂĐĨŨƠàáâãèéêếìíòóôõùúăđĩũơƯĂẠẢẤẦẨẪẬẮẰẲẴẶẸẺẼỀỀỂưăạảấầẩẫậắằẳẵặẹẻẽềềểỄỆỈỊỌỎỐỒỔỖỘỚỜỞỠỢỤỦỨỪễệỉịọỏốồổỗộớờởỡợụủứừỬỮỰỲỴÝỶỸửữựỳỵỷỹ].+', doc.paragraphs[i].text)        \n",
        "    if match != None:\n",
        "      tmp_str = match.group(0)\n",
        "      for idx in prefix:\n",
        "        tmp_str = tmp_str.replace(idx, \"\")\n",
        "      tmp_str = tmp_str.strip()\n",
        "      abstractLst.append(tmp_str)\n",
        "    \n",
        "  return abstractLst\n",
        "\n",
        "def extract_author_title(doc):\n",
        "  authorLst = []\n",
        "  titleLst = []\n",
        "  for i in range(len(doc.paragraphs)):\n",
        "    # Use for English only\n",
        "    # match = re.search('\\[[0-9]+\\]\\s+[a-zA-Z0-9].+', doc.paragraphs[i].text)\n",
        "    # Use for Vietnamese and English\n",
        "    match = re.search('^\\[[0-9]+\\]+\\s[a-zA-Z0-9a-zA-Z_ÀÁÂÃÈÉÊẾÌÍÒÓÔÕÙÚĂĐĨŨƠàáâãèéêếìíòóôõùúăđĩũơƯĂẠẢẤẦẨẪẬẮẰẲẴẶẸẺẼỀỀỂưăạảấầẩẫậắằẳẵặẹẻẽềềểỄỆỈỊỌỎỐỒỔỖỘỚỜỞỠỢỤỦỨỪễệỉịọỏốồổỗộớờởỡợụủứừỬỮỰỲỴÝỶỸửữựỳỵỷỹ].+', doc.paragraphs[i].text) # Use for Vietnamese\n",
        "    # result = (doc.paragraphs[i].text).startswith('[')\n",
        "    if match:\n",
        "      str_list = match.group(0)\n",
        "      author_list_split = str_list.split(\". \")\n",
        "      author_list_split = list(filter(str.strip, author_list_split))\n",
        "      name_author = \" \".join(author_list_split[:-1])\n",
        "      name_author = name_author.split()[1:]\n",
        "      name_author = \" \".join(name_author)\n",
        "\n",
        "      name_article = author_list_split[-1]\n",
        "      \n",
        "      authorLst.append(name_author)\n",
        "      titleLst.append(name_article.strip())\n",
        "    \n",
        "  return authorLst, titleLst\n",
        "\n",
        "def extract_index(doc):\n",
        "  indexLst = []\n",
        "  for i in range(len(doc.paragraphs)):\n",
        "    match = re.search(r'(?<!\\S)Paper index:\\s+(\\[[A-Za-z0-9].+)', doc.paragraphs[i].text)\n",
        "\n",
        "    if match:\n",
        "        idxLst = match.group(1).split(\",\")\n",
        "        for idx in idxLst:\n",
        "          idxStrip = idx.strip(\" []\")\n",
        "          indexLst.append(int(idxStrip))\n",
        "\n",
        "  return indexLst\n",
        "\n",
        "def extract_keywords(doc):\n",
        "  keywordLst = []\n",
        "  for i in range(len(doc.paragraphs)):\n",
        "    keywords = re.findall(\"Keywords:.+\", doc.paragraphs[i].text)\n",
        "    if (len(keywords) > 0):\n",
        "      tmp_str = ' '.join(keywords)\n",
        "      # Remove \"Keywords:\" word\n",
        "      prefix = [\"Keywords:\"]\n",
        "      for pre in prefix:\n",
        "        tmp_str = tmp_str[tmp_str.startswith(pre) and len(pre):]\n",
        "        tmp_str = \" \".join(tmp_str.split())\n",
        "\n",
        "      keywordLst.append(tmp_str)\n",
        "    \n",
        "  return keywordLst\n",
        "\n",
        "def extract_track(doc):\n",
        "  trackLst = []\n",
        "  for i in range(len(doc.paragraphs)):\n",
        "    track = re.findall(\"Track:.+\", doc.paragraphs[i].text)\n",
        "    if (len(track) > 0):\n",
        "      tmp_str = ' '.join(track)\n",
        "      # Remove \"Track:\" word\n",
        "      prefix = [\"Track:\"]\n",
        "      for pre in prefix:\n",
        "        tmp_str = tmp_str[tmp_str.startswith(pre) and len(pre):]\n",
        "        tmp_str = \" \".join(tmp_str.split())\n",
        "      trackLst.append(tmp_str)\n",
        "    \n",
        "  return trackLst\n",
        "\n",
        "def export_csv(index, track, author, title, keywords, abstract, folderName=None):\n",
        "  import pandas as pd\n",
        "\n",
        "  #make pandas df and store in runs folder\n",
        "  all_records = []\n",
        "\n",
        "  for i in range(len(author)):\n",
        "    all_records.append({'Index':index[i], 'Author':author[i], 'Title':title[i], 'Keywords':keywords[i], 'Track':track[i], 'Abstract':abstract[i]})\n",
        "\n",
        "  if folderName != None:\n",
        "    name_of_run = folderName\n",
        "  else:\n",
        "    name_of_run = 'fair2021_dataset'\n",
        "  \n",
        "  df_long   = pd.DataFrame(all_records, columns=['Index', 'Author', 'Title', 'Keywords', 'Track', 'Abstract'])\n",
        "  csv_name  = './' + 'fair2021_dataset.csv'\n",
        "  df_long[['Index', 'Author', 'Title', 'Keywords', 'Track', 'Abstract']].to_csv(csv_name, index=False)\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 334,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrAASLK57oMP",
        "outputId": "f785b6e1-797f-4765-85cb-0c24bad5c61c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "121\n",
            "121\n",
            "121\n",
            "121\n",
            "121\n",
            "121\n"
          ]
        }
      ],
      "source": [
        "index = extract_index(doc)\n",
        "track = extract_track(doc)\n",
        "keywords = extract_keywords(doc)\n",
        "author, title = extract_author_title(doc)\n",
        "abstract = extract_abstract(doc)\n",
        "print(len(index))\n",
        "print(len(track))\n",
        "print(len(keywords))\n",
        "print(len(author))\n",
        "print(len(title))\n",
        "print(len(abstract))\n",
        "# export_csv(index, track, author, title, keywords, abstract)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "export_csv(index, track, author, title, keywords, abstract)"
      ],
      "metadata": {
        "id": "E7S0TuPCNjlr"
      },
      "execution_count": 335,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5tCkqViY7UZV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}